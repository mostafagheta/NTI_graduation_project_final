apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: custom-alerts
  namespace: monitoring
  labels:
    release: prometheus
spec:
  groups:
  # Group 1: Node Alerts
  - name: node-alerts
    interval: 30s
    rules:
    # Alert 1: Node CPU > 80% for 5 minutes
    - alert: HighNodeCPU
      expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High CPU usage on node {{ $labels.instance }}"
        description: "Node CPU usage is above 80% (current value: {{ $value | humanize }}%)"
    
    # Alert 2: Node Memory > 80% for 5 minutes
    - alert: HighNodeMemory
      expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 80
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage on node {{ $labels.instance }}"
        description: "Node memory usage is above 80% (current value: {{ $value | humanize }}%)"
  
  # Group 2: Pod Alerts
  - name: pod-alerts
    interval: 30s
    rules:
    # Alert 3: Pod restarts > 3 in 5 minutes
    - alert: PodRestartingTooMuch
      expr: rate(kube_pod_container_status_restarts_total[5m]) * 300 > 3
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is restarting frequently"
        description: "Pod has restarted {{ $value | humanize }} times in the last 5 minutes"
    
    # Additional: Pod not ready
    - alert: PodNotReady
      expr: kube_pod_status_phase{phase!~"Running|Succeeded"} > 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is not ready"
        description: "Pod has been in {{ $labels.phase }} state for more than 5 minutes"
  
  # Group 3: Service Alerts
  - name: service-alerts
    interval: 30s
    rules:
    # Alert 4: Service unavailable (HTTP 5xx)
    - alert: HighHTTP5xxErrorRate
      expr: |
        sum(rate(http_requests_total{status=~"5.."}[5m])) by (service, namespace) 
        / 
        sum(rate(http_requests_total[5m])) by (service, namespace) 
        > 0.05
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High HTTP 5xx error rate on service {{ $labels.service }}"
        description: "Service {{ $labels.service }} in namespace {{ $labels.namespace }} has {{ $value | humanizePercentage }} HTTP 5xx errors"
    
    # Alternative: Service endpoint down (backup alert if app doesn't expose metrics)
    - alert: ServiceEndpointDown
      expr: up{job=~".*"} == 0
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "Service endpoint {{ $labels.job }} is down"
        description: "Service {{ $labels.job }} has been unreachable for more than 2 minutes"
    
    # Kubernetes service has no endpoints
    - alert: KubernetesServiceNoEndpoints
      expr: |
        sum by (namespace, service) (kube_endpoint_address_available{endpoint!~"kube-.*"})
        ==
        0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Kubernetes service {{ $labels.service }} has no endpoints"
        description: "Service {{ $labels.service }} in namespace {{ $labels.namespace }} has no available endpoints"
  
  # Group 4: Application-specific Alerts
  - name: application-alerts
    interval: 30s
    rules:
    # Netflix app specific
    - alert: NetflixAppDown
      expr: kube_deployment_status_replicas_available{namespace="netflix",deployment="netflix-clone"} == 0
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "Netflix Clone application is down"
        description: "No replicas available for netflix-clone deployment in namespace netflix"
